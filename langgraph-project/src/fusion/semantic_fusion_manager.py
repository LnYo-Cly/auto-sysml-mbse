# step4_semantic_fusion/semantic_fusion_manager.py

import sys
import os
import logging
import concurrent.futures
from typing import Dict, Any, Optional, Tuple, List

from flask import json

logger = logging.getLogger(__name__)

# è®¾ç½®é¡¹ç›®æ ¹ç›®å½•ä»¥ä¾¿å¯¼å…¥æ¨¡å—
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from connections import config
from connections.database_connectors import get_pg_connection, setup_pgvector_table
from connections.embedding_client import OllamaEmbeddingClient, GLMEmbeddingClient
from fusion.llm_arbiter import LLMArbiter # <--- å¯¼å…¥æ–°çš„ä»²è£è€…
from config.settings import settings


# å®šä¹‰ç›¸ä¼¼åº¦ç»“æœçš„æ•°æ®ç»“æ„
SemanticSearchResult = Tuple[bool, Optional[str], Optional[float]]

class SemanticFusionManager:
    """
    è´Ÿè´£é€šè¿‡å‘é‡ç›¸ä¼¼åº¦æ¥è¯†åˆ«æ½œåœ¨çš„é‡å¤å®ä½“ã€‚
    """
    # ä½™å¼¦ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œåªæœ‰é«˜äºæ­¤å€¼çš„æ‰è¢«è®¤ä¸ºæ˜¯å¼ºç›¸ä¼¼
    SIMILARITY_THRESHOLD = 0.98

    def __init__(self):
        """åˆå§‹åŒ–ç®¡ç†å™¨ï¼Œè¿æ¥pgvectorå¹¶å‡†å¤‡Ollamaå®¢æˆ·ç«¯ã€‚"""
        self.pg_conn = get_pg_connection()
        # self.embed_client = GLMEmbeddingClient()
        if settings.embedding_service == "ollama":
            self.embed_client = OllamaEmbeddingClient()
        elif settings.embedding_service == "glm":
            self.embed_client = GLMEmbeddingClient()

        self.llm_arbiter = LLMArbiter() # <--- åœ¨è¿™é‡Œåˆå§‹åŒ–ä»²è£è€…
        if not self.pg_conn or not self.embed_client.client:
            raise ConnectionError("æ— æ³•åˆå§‹åŒ–SemanticFusionManagerï¼Œè¯·æ£€æŸ¥æ•°æ®åº“æˆ–Ollamaè¿æ¥ã€‚")
        # âœ… åˆå§‹åŒ–æ—¶æ£€æŸ¥å¹¶åˆ›å»ºè¡¨
        self._ensure_table_exists()
        print("SemanticFusionManager åˆå§‹åŒ–æˆåŠŸã€‚")

    def _ensure_table_exists(self):
        """
        æ£€æŸ¥ pgvector è¡¨æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
        """
        try:
            with self.pg_conn.cursor() as cursor:
                # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
                cursor.execute("""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables 
                        WHERE table_name = %s
                    );
                """, (config.PG_VECTOR_TABLE_NAME,))
                
                table_exists = cursor.fetchone()[0]
                
                if not table_exists:
                    print(f"âš ï¸ è¡¨ '{config.PG_VECTOR_TABLE_NAME}' ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º...")
                    if setup_pgvector_table(self.pg_conn):
                        print(f"âœ… è¡¨ '{config.PG_VECTOR_TABLE_NAME}' åˆ›å»ºæˆåŠŸ")
                    else:
                        raise Exception(f"æ— æ³•åˆ›å»ºè¡¨ '{config.PG_VECTOR_TABLE_NAME}'")
                else:
                    print(f"âœ… è¡¨ '{config.PG_VECTOR_TABLE_NAME}' å·²å­˜åœ¨")
                    
        except Exception as e:
            print(f"âŒ æ£€æŸ¥è¡¨å¤±è´¥: {e}")
            raise

    def find_similar_element(self, element: Dict[str, Any], canonical_key: str) -> SemanticSearchResult:
        """
        åœ¨å‘é‡æ•°æ®åº“ä¸­æŸ¥æ‰¾ä¸ç»™å®šå…ƒç´ è¯­ä¹‰ä¸Šæœ€ç›¸ä¼¼çš„å®ä½“ã€‚

        Args:
            element (Dict[str, Any]): å¾…æ£€æŸ¥çš„å…ƒç´ å¯¹è±¡ã€‚

        Returns:
            ä¸€ä¸ªå…ƒç»„ (is_similar, similar_key, similarity_score)ï¼Œ
            å¦‚æœæ‰¾åˆ°å¼ºç›¸ä¼¼é¡¹ï¼Œis_similarä¸ºTrueã€‚
        """
        element_name = element.get('name')
        element_type = element.get('type')
        
        print("\nå¼€å§‹è¯­ä¹‰ç›¸ä¼¼æ€§æ£€æŸ¥")

        # å¦‚æœå…ƒç´ æ²¡æœ‰åç§°æˆ–ç±»å‹ï¼Œåˆ™æ— æ³•è¿›è¡Œæœ‰æ„ä¹‰çš„è¯­ä¹‰æ¯”è¾ƒ
        if not element_name or not element_type:
            return (False, None, None)

        # 1. ä¸ºå½“å‰å…ƒç´ çš„åç§°ç”ŸæˆåµŒå…¥å‘é‡
        # å¦‚æœæœ‰ descriptionï¼Œåˆ™åŒ…å«åœ¨å‘é‡ç”Ÿæˆä¸­ä»¥æå‡è¯­ä¹‰å‡†ç¡®åº¦
        element_desc = element.get('description', '')
        if element_desc:
            text_to_embed = f"A {element_type} named {element_name}: {element_desc}"
        else:
            text_to_embed = f"A {element_type} named {element_name}"
        
        print(f"  text_to_embed: {text_to_embed}")
        embedding = self.embed_client.get_embedding(text_to_embed)
        if not embedding:
            print(f"  - è­¦å‘Š: æ— æ³•ä¸º '{element_name}' ç”Ÿæˆå‘é‡ï¼Œè·³è¿‡è¯­ä¹‰æ£€æŸ¥ã€‚")
            return (False, None, None)

        # 2. åœ¨pgvectorä¸­æ‰§è¡Œç›¸ä¼¼åº¦æœç´¢
        # '<=>' æ˜¯pgvectoræä¾›çš„ä½™å¼¦è·ç¦»è¿ç®—ç¬¦ (0=å®Œå…¨ç›¸åŒ, 1=ä¸ç›¸å…³)
        # ç›¸ä¼¼åº¦ = 1 - è·ç¦»
        # é‡è¦: æ’é™¤å½“å‰å…ƒç´ æœ¬èº«ï¼Œé¿å…æ‰¾åˆ°è‡ªå·±
        # åŒæ—¶è·å– description ç”¨äº LLM ä»²è£
        query = f"""
        SELECT canonical_key, element_description, 1 - (embedding <=> %s) AS similarity
        FROM {config.PG_VECTOR_TABLE_NAME}
        WHERE element_type = %s AND canonical_key != %s
        ORDER BY similarity DESC
        LIMIT 1;
        """
        
        with self.pg_conn.cursor() as cursor:
            # psycopg2éœ€è¦å°†listè½¬æ¢ä¸ºå­—ç¬¦ä¸²
            cursor.execute(query, (str(embedding), element_type, canonical_key))
            result = cursor.fetchone()
            
        if result:
            similar_key, similar_desc, similarity_score = result
            if similarity_score >= self.SIMILARITY_THRESHOLD:
                # æ‰¾åˆ°äº†ä¸€ä¸ªå¼ºç›¸ä¼¼çš„å®ä½“ï¼Œç°åœ¨è§¦å‘LLMä»²è£
                print(f"\n  - å‘é‡å¬å›: æ‰¾åˆ°æ½œåœ¨ç›¸ä¼¼é¡¹ '{canonical_key}' -> '{similar_key}' (ç›¸ä¼¼åº¦: {similarity_score:.2f})")
                
                # ä¼ é€’å½“å‰å…ƒç´ å’Œç›¸ä¼¼å…ƒç´ çš„ description ç»™ LLM ä»²è£
                is_truly_same = self.llm_arbiter.are_they_the_same_entity(
                    canonical_key,
                    element_desc,
                    similar_key,
                    similar_desc or ''  # å¦‚æœ similar_desc ä¸º Noneï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²
                )
                
                if is_truly_same:
                    # åªæœ‰åœ¨LLMç¡®è®¤åï¼Œæ‰åˆ¤å®šä¸ºé‡å¤
                    return (True, similar_key, similarity_score)

        # æœªæ‰¾åˆ°å¼ºç›¸ä¼¼å®ä½“
    
        return (False, None, None)

    def store_element_embedding(self, element: Dict[str, Any], canonical_key: str):
        """
        å°†ä¸€ä¸ªæ–°ç¡®è®¤çš„å…ƒç´ çš„å‘é‡å­˜å…¥pgvectorã€‚

        Args:
            element (Dict[str, Any]): è¦å­˜å‚¨çš„å…ƒç´ å¯¹è±¡ã€‚
            canonical_key (str): è¯¥å…ƒç´ çš„è§„èŒƒé”®ã€‚
        """

        
        element_name = element.get('name')
        element_type = element.get('type')
        element_desc = element.get('description', '')  # è·å– descriptionï¼Œå¦‚æœæ²¡æœ‰åˆ™ä¸ºç©ºå­—ç¬¦ä¸²


        # æ²¡æœ‰ name å°±ç”¨ canonical_key çš„æœ€åä¸€éƒ¨åˆ†
        if not element_name:
            element_name = canonical_key.split('::')[-1]
        if not element_type:
            print("  âš ï¸ å…ƒç´ ç¼ºå°‘ typeï¼Œè·³è¿‡å­˜å‚¨")
            return # æ²¡æœ‰è¶³å¤Ÿä¿¡æ¯ï¼Œä¸å­˜å‚¨

        # ç”Ÿæˆ embedding æ—¶åŒ…å« descriptionï¼ˆä¸ find_similar_element ä¿æŒä¸€è‡´ï¼‰
        if isinstance(element_desc, dict):
            element_desc = json.dumps(element_desc, ensure_ascii=False)
            text_to_embed = f"A {element_type} named {element_name}: {element_desc}"
        
        elif element_desc:
            text_to_embed = f"A {element_type} named {element_name}: {element_desc}"
        else:
            text_to_embed = f"A {element_type} named {element_name}"
        
        print(f"  text_to_embed: {text_to_embed}")

        embedding = self.embed_client.get_embedding(text_to_embed)
        if not embedding:
            return

        # âœ… è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²ç”¨äºæŸ¥è¯¢
        if isinstance(embedding, (list, dict)):
            embedding_json = json.dumps(embedding)
        else:
            embedding_json = str(embedding)

        # ä½¿ç”¨ INSERT ... ON CONFLICT (UPSERT) è¯­å¥ï¼Œç¡®ä¿ä¸»é”®å”¯ä¸€
        query = f"""
        INSERT INTO {config.PG_VECTOR_TABLE_NAME} (canonical_key, element_name, element_type, element_description, embedding)
        VALUES (%s, %s, %s, %s, %s)
        ON CONFLICT (canonical_key) DO UPDATE SET
            element_name = EXCLUDED.element_name,
            element_description = EXCLUDED.element_description,
            embedding = EXCLUDED.embedding;
        """
        # ========== æ·»åŠ è°ƒè¯•æ‰“å° ==========
        print(f"\n  [DEBUG] å‡†å¤‡æ‰§è¡Œ SQL")
        print(f"    è¡¨å: {config.PG_VECTOR_TABLE_NAME}")
        
        params = (canonical_key, element_name, element_type, element_desc, embedding_json)
        print(f"  [DEBUG] SQL å‚æ•°:")
        for i, param in enumerate(params):
            print(f"    å‚æ•° {i}: ç±»å‹={type(param)}, å€¼={str(param)[:100]}...")
        # ==================================
        
        with self.pg_conn.cursor() as cursor:
            cursor.execute(query, (canonical_key, element_name, element_type, element_desc, str(embedding_json)))
        self.pg_conn.commit()
    
    def get_embeddings_parallel(self, items: List[Tuple[str, str]]) -> List[Optional[List[float]]]:
        """
        å¹¶è¡Œç”Ÿæˆå‘é‡
        
        Args:
            items: List of (text_to_embed, identifier_for_log)
            
        Returns:
            List[Optional[List[float]]]: å¯¹åº”æ¯ä¸ªæ–‡æœ¬çš„åµŒå…¥å‘é‡
        """
        if not items:
            return []
        
        embeddings = [None] * len(items)
        
        def _worker(index, text, identifier):
            try:
                embedding = self.embed_client.get_embedding(text)
                if embedding:
                    logger.debug(f"âœ… [{index}] å‘é‡ç”ŸæˆæˆåŠŸ: {identifier}")
                return index, embedding
            except Exception as e:
                logger.error(f"âŒ [{index}] å‘é‡ç”Ÿæˆå¤±è´¥ ({identifier}): {e}")
                return index, None
        
        max_workers = min(len(items), 10)  # æœ€å¤š10ä¸ªå¹¶å‘
        logger.info(f"ğŸš€ å¼€å§‹å¹¶è¡Œç”Ÿæˆ {len(items)} ä¸ªå‘é‡ (å¹¶å‘æ•°: {max_workers})")
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = [executor.submit(_worker, i, item[0], item[1]) for i, item in enumerate(items)]
            
            for future in concurrent.futures.as_completed(futures):
                idx, emb = future.result()
                embeddings[idx] = emb
        
        success_count = sum(1 for e in embeddings if e is not None)
        logger.info(f"âœ… å¹¶è¡Œå‘é‡ç”Ÿæˆå®Œæˆ: {success_count}/{len(items)} æˆåŠŸ")
        
        return embeddings
    
    def search_candidate_only(self, embedding: List[float], element_type: str, canonical_key: str) -> Optional[Dict[str, Any]]:
        """
        ä»…æœç´¢ç›¸ä¼¼å€™é€‰ï¼Œä¸è¿›è¡Œ LLM ä»²è£
        
        Args:
            embedding: åµŒå…¥å‘é‡
            element_type: å…ƒç´ ç±»å‹
            canonical_key: è§„èŒƒé”®
            
        Returns:
            å¦‚æœæ‰¾åˆ°ç›¸ä¼¼å€™é€‰ï¼Œè¿”å› {'key': str, 'description': str, 'similarity': float}
        """
        query = f"""
        SELECT canonical_key, element_description, 1 - (embedding <=> %s) AS similarity
        FROM {config.PG_VECTOR_TABLE_NAME}
        WHERE element_type = %s AND canonical_key != %s
        ORDER BY similarity DESC
        LIMIT 1;
        """
        
        with self.pg_conn.cursor() as cursor:
            cursor.execute(query, (str(embedding), element_type, canonical_key))
            result = cursor.fetchone()
        
        if result:
            similar_key, similar_desc, similarity_score = result
            if similarity_score >= self.SIMILARITY_THRESHOLD:
                return {
                    'key': similar_key,
                    'description': similar_desc or '',
                    'similarity': similarity_score
                }
        
        return None
    
    def store_embedding_direct(self, canonical_key: str, element: Dict[str, Any], embedding: List[float]):
        """
        ç›´æ¥å­˜å‚¨åµŒå…¥å‘é‡ï¼ˆä¸å†é‡æ–°ç”Ÿæˆï¼‰
        
        Args:
            canonical_key: è§„èŒƒé”®
            element: å…ƒç´ æ•°æ®
            embedding: å·²ç”Ÿæˆçš„åµŒå…¥å‘é‡
        """
        element_name = element.get('name', canonical_key.split('::')[-1])
        element_type = element.get('type')
        element_desc = element.get('description', '')
        
        if not element_type:
            logger.warning(f"âš ï¸ å…ƒç´ ç¼ºå°‘ typeï¼Œè·³è¿‡å­˜å‚¨: {canonical_key}")
            return
        
        # å¤„ç† description
        if isinstance(element_desc, dict):
            element_desc = json.dumps(element_desc, ensure_ascii=False)
        
        # è½¬æ¢å‘é‡ä¸º JSON å­—ç¬¦ä¸²
        if isinstance(embedding, (list, dict)):
            embedding_json = json.dumps(embedding)
        else:
            embedding_json = str(embedding)
        
        query = f"""
        INSERT INTO {config.PG_VECTOR_TABLE_NAME} (canonical_key, element_name, element_type, element_description, embedding)
        VALUES (%s, %s, %s, %s, %s)
        ON CONFLICT (canonical_key) DO UPDATE SET
            element_name = EXCLUDED.element_name,
            element_description = EXCLUDED.element_description,
            embedding = EXCLUDED.embedding;
        """
        
        try:
            with self.pg_conn.cursor() as cursor:
                cursor.execute(query, (canonical_key, element_name, element_type, element_desc, str(embedding_json)))
            self.pg_conn.commit()
            logger.debug(f"âœ… å‘é‡å­˜å‚¨æˆåŠŸ: {canonical_key}")
        except Exception as e:
            logger.error(f"âŒ å‘é‡å­˜å‚¨å¤±è´¥ ({canonical_key}): {e}")
