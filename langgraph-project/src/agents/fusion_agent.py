"""
èåˆAgent - è´Ÿè´£æ•´åˆæ‰€æœ‰SysMLå›¾çš„JSONè¾“å‡ºï¼Œæ„å»ºç»Ÿä¸€çš„çŸ¥è¯†å›¾è°±
åŸºäº master-2/step5_relationship_building/run_step5_final_pipeline.py æ”¹é€ 
"""
import logging
import json
import os
from typing import Dict, Any, List
from datetime import datetime

from graph.workflow_state import WorkflowState, ProcessStatus
from config.settings import settings

logger = logging.getLogger(__name__)

def collect_diagram_json_paths(state: WorkflowState) -> List[str]:
    """
    æ”¶é›†æ‰€æœ‰å·²å®Œæˆä»»åŠ¡çš„ JSON æ–‡ä»¶è·¯å¾„
    
    è¿”å›:
        JSONæ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    json_paths = []
    
    for task in state.assigned_tasks:
        if task.status == ProcessStatus.COMPLETED and task.result:
            if isinstance(task.result, dict) and "saved_file" in task.result:
                json_path = task.result["saved_file"]
                if os.path.exists(json_path):
                    json_paths.append(json_path)
                    logger.info(f"âœ… å·²æ”¶é›† {task.type} å›¾çš„JSON: {json_path}")
                else:
                    logger.warning(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {json_path}")
    
    logger.info(f"ğŸ“Š å…±æ”¶é›†åˆ° {len(json_paths)} ä¸ªJSONæ–‡ä»¶")
    return json_paths


def run_fusion_pipeline(json_paths: List[str]) -> Dict[str, Any]:
    """
    æ‰§è¡Œå®Œæ•´çš„èåˆæµç¨‹
    
    è¿™æ˜¯ master-2/step5_relationship_building/run_step5_final_pipeline.py çš„ main() å‡½æ•°æ”¹é€ ç‰ˆæœ¬
    
    å‚æ•°:
        json_paths: JSONæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        
    è¿”å›:
        èåˆç»“æœå­—å…¸
    """
    print("--- æœ€ç»ˆèåˆç®¡é“: æ­¥éª¤ 1-7 (åŒ…å«å…³ç³»é‡å»º + æ¨¡å‹ç»Ÿä¸€) ---")
    
    # å¯¼å…¥ master-2 çš„æ¨¡å—ï¼ˆæ‚¨éœ€è¦å…ˆè¿ç§»è¿™äº›æ¨¡å—åˆ°é¡¹ç›®ä¸­ï¼‰
    try:
        from fusion.jsontokey import CanonicalKeyGenerator, load_json_files
        from fusion.neo4j_fusion_manager import Neo4jFusionManager
        from fusion.semantic_fusion_manager import SemanticFusionManager
        from connections.database_connectors import close_connections
        from exports.neo4j_to_json import JsonReverser 
    except ImportError as e:
        logger.error(f"âŒ å¯¼å…¥èåˆæ¨¡å—å¤±è´¥: {e}")
        return {"status": "error", "message": f"æ¨¡å—å¯¼å…¥å¤±è´¥: {e}"}
    
    # --- æ­¥éª¤ 1: å‡†å¤‡æ•°æ® ---
    print("\n[1/7] æ­£åœ¨åŠ è½½ã€è§£æå¹¶ç”Ÿæˆè§„èŒƒé”®...")
    try:
        # ä½¿ç”¨æ”¶é›†åˆ°çš„JSONæ–‡ä»¶è·¯å¾„ï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç çš„è·¯å¾„
        master_element_list = load_json_files(*json_paths)
        all_elements_map = {elem['id']: elem for elem in master_element_list}
        key_generator = CanonicalKeyGenerator(master_element_list)
        elements_with_keys = key_generator.generate_all_keys()
        print(f"  âœ… æ•°æ®å‡†å¤‡å®Œæˆã€‚å…±å¤„ç† {len(master_element_list)} ä¸ªå…ƒç´ ã€‚")
        logger.info(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆ: {len(master_element_list)} ä¸ªå…ƒç´ ")
    except FileNotFoundError as e:
        error_msg = f"æ–‡ä»¶æœªæ‰¾åˆ°: {e}"
        print(f"âŒ é”™è¯¯: {error_msg}")
        logger.error(f"âŒ {error_msg}")
        return {"status": "error", "message": error_msg}
    except Exception as e:
        error_msg = f"æ•°æ®å‡†å¤‡å¤±è´¥: {e}"
        print(f"âŒ é”™è¯¯: {error_msg}")
        logger.error(f"âŒ {error_msg}", exc_info=True)
        return {"status": "error", "message": error_msg}

    neo4j_manager = None
    semantic_manager = None
    canonical_key_remap = {}  # åˆå§‹åŒ–é‡æ˜ å°„è¡¨
    
    try:
        # --- æ­¥éª¤ 2: åˆå§‹åŒ–ç®¡ç†å™¨ ---
        print("\n[2/7] æ­£åœ¨åˆå§‹åŒ–æ‰€æœ‰ç®¡ç†å™¨...")
        neo4j_manager = Neo4jFusionManager()
        semantic_manager = SemanticFusionManager()
        print("  âœ… ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆã€‚")
        logger.info("âœ… ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")

        # --- æ­¥éª¤ 3: æ¸…ç©ºæ•°æ®åº“å¹¶è®¾ç½®çº¦æŸ ---
        print("\n[3/7] æ­£åœ¨æ¸…ç©ºæ•°æ®åº“å¹¶è®¾ç½®çº¦æŸ (ä¸ºäº†å¹‚ç­‰æ€§)...")
        neo4j_manager._execute_write("MATCH (n) DETACH DELETE n")
        print("  - æ—§æ•°æ®å·²æ¸…ç©ºã€‚")
        logger.info("- æ—§æ•°æ®å·²æ¸…ç©º")
        neo4j_manager.setup_constraints(master_element_list)
        print("  âœ… çº¦æŸè®¾ç½®å®Œæˆã€‚")
        logger.info("âœ… çº¦æŸè®¾ç½®å®Œæˆ")

        # --- æ­¥éª¤ 4: è¿­ä»£èåˆ ---
        print("\n[4/7] å¼€å§‹è¿­ä»£èåˆï¼ˆè¯­ä¹‰æ£€æŸ¥ + ç»“æ„åŒ–å†™å…¥ï¼‰...")
        logger.info("ğŸ”„ å¼€å§‹è¿­ä»£èåˆ...")
        
        processed_count = 0
        similar_count = 0
        
        for original_id, canonical_key in elements_with_keys.items():
            element_data = all_elements_map.get(original_id)
            if not element_data:
                continue
            
            # è¯­ä¹‰ç›¸ä¼¼æ€§æ£€æŸ¥
            is_similar, similar_key, _ = semantic_manager.find_similar_element(
                element_data, canonical_key
            )
            
            if is_similar:
                canonical_key_remap[canonical_key] = similar_key
                similar_count += 1
                continue
            
            # å†™å…¥Neo4j
            neo4j_manager.fuse_element(element_data, canonical_key)
            # å­˜å‚¨è¯­ä¹‰åµŒå…¥
            semantic_manager.store_element_embedding(element_data, canonical_key)
            processed_count += 1
        
        print(f"\n  âœ… è¿­ä»£èåˆå®Œæˆã€‚å¤„ç†äº† {processed_count} ä¸ªæ–°å…ƒç´ ï¼Œè·³è¿‡ {similar_count} ä¸ªç›¸ä¼¼å…ƒç´ ã€‚")
        logger.info(f"âœ… è¿­ä»£èåˆå®Œæˆ: æ–°å…ƒç´ ={processed_count}, ç›¸ä¼¼å…ƒç´ ={similar_count}")

        # --- æ­¥éª¤ 5: å…³ç³»é‡å»º ---
        print("\n[5/7] å¼€å§‹å…³ç³»é‡å»ºæµç¨‹...")
        logger.info("ğŸ”— å¼€å§‹å…³ç³»é‡å»º...")
        neo4j_manager.rebuild_relationships(
            all_elements_map,
            elements_with_keys,
            canonical_key_remap
        )
        print("  âœ… å…³ç³»é‡å»ºå®Œæˆã€‚")
        logger.info("âœ… å…³ç³»é‡å»ºå®Œæˆ")
        
        # --- æ­¥éª¤ 6: æ¨¡å‹ç»Ÿä¸€ ---
        print("\n[6/7] æ­£åœ¨ç»Ÿä¸€æ¨¡å‹æ ¹...")
        logger.info("ğŸ¯ æ­£åœ¨ç»Ÿä¸€æ¨¡å‹æ ¹...")
        neo4j_manager.unify_models(
            master_model_original_id="master-model",
            master_model_name="Model"  # æ‚¨å¯ä»¥è‡ªå®šä¹‰åç§°
        )
        print("  âœ… æ¨¡å‹ç»Ÿä¸€å®Œæˆã€‚")
        logger.info("âœ… æ¨¡å‹ç»Ÿä¸€å®Œæˆ")
        
        # --- æ­¥éª¤ 7: å¯¼å‡ºæœ€ç»ˆç»“æœï¼ˆå¯é€‰ï¼‰ ---
        print("\n[7/7] æ­£åœ¨å¯¼å‡ºèåˆç»“æœ...")
        logger.info("ğŸ’¾ æ­£åœ¨å¯¼å‡ºèåˆç»“æœ...")
        
        # ä»Neo4jå¯¼å‡ºç»Ÿä¸€çš„JSONï¼ˆæ‚¨å¯èƒ½éœ€è¦ä» master-2 å®ç°è¿™ä¸ªåŠŸèƒ½ï¼‰
        try:
            # è¿™é‡Œå‡è®¾æœ‰ä¸€ä¸ªå¯¼å‡ºå‡½æ•°ï¼Œæ‚¨éœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
            final_json = neo4j_manager.export_to_json()
            logger.info("âœ… èåˆç»“æœå¯¼å‡ºå®Œæˆ")
        except AttributeError:
            # å¦‚æœæ²¡æœ‰å¯¼å‡ºåŠŸèƒ½ï¼Œè¿”å›ç»Ÿè®¡ä¿¡æ¯
            logger.warning("âš ï¸ æœªå®ç°å¯¼å‡ºåŠŸèƒ½ï¼Œè¿”å›ç»Ÿè®¡ä¿¡æ¯")
            final_json = {
                "total_elements": len(master_element_list),
                "processed_elements": processed_count,
                "similar_elements": similar_count,
                "canonical_key_remap": canonical_key_remap
            }
        
        # --- æ­¥éª¤ 7: å¯¼å‡ºæœ€ç»ˆç»“æœ ---
        print("\n[7/7] æ­£åœ¨ä»Neo4jå¯¼å‡ºèåˆåçš„JSON...")
        logger.info("ğŸ’¾ æ­£åœ¨ä»Neo4jå¯¼å‡ºèåˆåçš„JSON...")
        
        # âœ… ä½¿ç”¨ JsonReverser ä» Neo4j å¯¼å‡ºå®Œæ•´çš„ JSON
        try:
            reverser = JsonReverser()
            final_json = reverser.reconstruct_json()
            logger.info("âœ… èåˆç»“æœå¯¼å‡ºæˆåŠŸ")
            print("  âœ… JSONå¯¼å‡ºæˆåŠŸ")
        except Exception as export_error:
            logger.warning(f"âš ï¸ JSONå¯¼å‡ºå¤±è´¥ï¼Œä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯æ›¿ä»£: {export_error}")
            print(f"  âš ï¸ JSONå¯¼å‡ºå¤±è´¥: {export_error}")
            final_json = {
                "model": [],
                "elements": [],
                "statistics": {
                    "total_elements": len(master_element_list),
                    "processed_elements": processed_count,
                    "similar_elements": similar_count
                }
            }
        
        print("\nâœ… [7/7] ç®¡é“æ‰§è¡ŒæˆåŠŸï¼")
        logger.info("âœ… èåˆç®¡é“æ‰§è¡ŒæˆåŠŸ")
        
        return {
            "status": "success",
            "result": final_json,
            "statistics": {
                "total_elements": len(master_element_list),
                "processed_elements": processed_count,
                "similar_elements": similar_count,
                "total_fused_elements": len(final_json.get("elements", [])) if isinstance(final_json, dict) else 0
            }
        }
        
    except (ConnectionError, Exception) as e:
        error_msg = f"ç®¡é“æ‰§è¡Œå¤±è´¥: {e}"
        print(f"\nâŒ {error_msg}")
        logger.error(f"âŒ {error_msg}", exc_info=True)
        return {"status": "error", "message": error_msg}
    
    finally:
        print("\næ­£åœ¨å…³é—­æ‰€æœ‰æ•°æ®åº“è¿æ¥...")
        logger.info("æ­£åœ¨å…³é—­æ‰€æœ‰æ•°æ®åº“è¿æ¥...")
        close_connections()
        print("âœ… æ¸…ç†å®Œæˆã€‚")
        logger.info("âœ… æ¸…ç†å®Œæˆ")


def fusion_agent(state: WorkflowState) -> WorkflowState:
    """
    èåˆAgentä¸»å‡½æ•° - LangGraphå·¥ä½œæµèŠ‚ç‚¹
    
    åŠŸèƒ½:
        1. æ”¶é›†æ‰€æœ‰å·²å®Œæˆä»»åŠ¡çš„JSONè¾“å‡º
        2. æ‰§è¡Œèåˆæµç¨‹ï¼ˆNeo4j + è¯­ä¹‰èåˆï¼‰
        3. ä¿å­˜èåˆç»“æœ
        
    å‚æ•°:
        state: å½“å‰å·¥ä½œæµçŠ¶æ€
        
    è¿”å›:
        æ›´æ–°åçš„å·¥ä½œæµçŠ¶æ€
    """
    logger.info("=" * 80)
    logger.info("ğŸ”— èåˆAgentå¼€å§‹å·¥ä½œ")
    logger.info("=" * 80)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å·²å®Œæˆçš„ä»»åŠ¡
    completed_tasks = [
        t for t in state.assigned_tasks 
        if t.status == ProcessStatus.COMPLETED
    ]
    
    if not completed_tasks:
        logger.warning("âš ï¸ æ²¡æœ‰å·²å®Œæˆçš„ä»»åŠ¡ï¼Œè·³è¿‡èåˆæ­¥éª¤")
        state.fusion_status = "skipped"
        state.fusion_message = "æ²¡æœ‰å·²å®Œæˆçš„ä»»åŠ¡"
        return state
    
    try:
        # 1. æ”¶é›†æ‰€æœ‰å›¾çš„JSONæ–‡ä»¶è·¯å¾„
        json_paths = collect_diagram_json_paths(state)
        
        if not json_paths:
            logger.warning("âš ï¸ æ²¡æœ‰å¯ç”¨çš„JSONæ–‡ä»¶ï¼Œè·³è¿‡èåˆæ­¥éª¤")
            state.fusion_status = "skipped"
            state.fusion_message = "æ²¡æœ‰å¯ç”¨çš„JSONæ–‡ä»¶"
            return state
        
        # 2. æ‰§è¡Œèåˆæµç¨‹
        fusion_result = run_fusion_pipeline(json_paths)
        
        if fusion_result["status"] == "success":
            # 3. ä¿å­˜èåˆç»“æœ
            output_dir = os.path.join(
                os.path.dirname(os.path.dirname(__file__)), 
                "data", "output", "fusion"
            )
            os.makedirs(output_dir, exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = os.path.join(output_dir, f"fused_model_{timestamp}.json")
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(fusion_result["result"], f, ensure_ascii=False, indent=2)
            
            logger.info(f"âœ… èåˆç»“æœå·²ä¿å­˜: {output_path}")
            
            # æ›´æ–°çŠ¶æ€
            state.fusion_status = "completed"
            state.fusion_output_path = output_path
            state.fusion_statistics = fusion_result.get("statistics", {})
            
        else:
            logger.error(f"âŒ èåˆå¤±è´¥: {fusion_result.get('message')}")
            state.fusion_status = "failed"
            state.fusion_message = fusion_result.get('message')
    
    except Exception as e:
        logger.error(f"âŒ èåˆAgentå¼‚å¸¸: {e}", exc_info=True)
        state.fusion_status = "failed"
        state.fusion_message = str(e)
    
    logger.info("=" * 80)
    logger.info(f"ğŸ”— èåˆAgentå®Œæˆï¼ŒçŠ¶æ€: {state.fusion_status}")
    logger.info("=" * 80)
    
    return state