"""
ä»»åŠ¡åˆ†ç±»Agent
å¯¹æ–‡æ¡£chunksè¿›è¡Œåˆ†ç±»ï¼Œæå–SysMLä»»åŠ¡
"""
import logging
import uuid
import json
import os
from typing import List
from collections import defaultdict
from datetime import datetime

from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field
from json_repair import repair_json

from graph.workflow_state import WorkflowState, SysMLTask, ProcessStatus
from config.settings import settings

logger = logging.getLogger(__name__)

# å¯¼å…¥å„ä¸ªsysml-agent
try:
    from agents.diagram_agents.req_agent import requirement_agent
except ImportError as e:
    logger.warning(f"æ— æ³•å¯¼å…¥éœ€æ±‚å›¾Agent: {e}")
    requirement_agent = None
    
try:
    from agents.diagram_agents.act_agent import activity_agent
except ImportError as e:
    logger.warning(f"æ— æ³•å¯¼å…¥æ´»åŠ¨å›¾Agent: {e}")
    activity_agent = None
    
try:
    from agents.diagram_agents.bdd_ibd_agent import bdd_ibd_agent
except ImportError as e:
    logger.warning(f"æ— æ³•å¯¼å…¥BDD/IBDå›¾Agent: {e}")
    bdd_ibd_agent = None
    
try:
    from agents.diagram_agents.par_agent import parameter_agent
except ImportError as e:
    logger.warning(f"æ— æ³•å¯¼å…¥å‚æ•°å›¾Agent: {e}")
    parameter_agent = None
    
try:
    from agents.diagram_agents.uc_agent import usecase_agent
except ImportError as e:
    logger.warning(f"æ— æ³•å¯¼å…¥ç”¨ä¾‹å›¾Agent: {e}")
    usecase_agent = None
    
try:
    from agents.diagram_agents.stm_agent import state_machine_agent
except ImportError as e:
    logger.warning(f"æ— æ³•å¯¼å…¥çŠ¶æ€æœºå›¾Agent: {e}")
    state_machine_agent = None
    
try:
    from agents.diagram_agents.sd_agent import sequence_agent
except ImportError as e:
    logger.warning(f"æ— æ³•å¯¼å…¥åºåˆ—å›¾Agent: {e}")
    sequence_agent = None


class SysMLTaskExtraction(BaseModel):
    """SysMLä»»åŠ¡æå–ç»“æœé¡¹"""
    type: str = Field(description="SysMLå›¾è¡¨ç±»å‹")
    content: str = Field(description="æå–çš„ç›¸å…³å†…å®¹")


class SysMLTaskExtractionResult(BaseModel):
    """SysMLä»»åŠ¡æå–ç»“æœé›†åˆ"""
    tasks: List[SysMLTaskExtraction] = Field(description="æå–çš„SysMLä»»åŠ¡åˆ—è¡¨")


# ç³»ç»Ÿæç¤ºæ¨¡æ¿
SYSTEM_PROMPT_EXTRACT_AND_CLASSIFY = """
ä½ æ˜¯ä¸€ä¸ªç³»ç»Ÿè®¾è®¡åŠ©æ‰‹ï¼Œä¸“æ³¨äºMBSEï¼ˆModel-Based Systems Engineeringï¼‰ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†ææä¾›çš„æ–‡æœ¬å†…å®¹ï¼Œç²¾ç¡®è¯†åˆ«å…¶ä¸­åŒ…å«çš„SysMLæ¨¡å‹ç›¸å…³ä¿¡æ¯ï¼Œå¹¶å°†å®ƒä»¬åˆ†ç±»ä»¥ä¾¿åˆ†é…ç»™ä¸“é—¨çš„SysMLå»ºæ¨¡Agentã€‚

è¯·å°†è¯†åˆ«å‡ºçš„ä¿¡æ¯å½’ç±»ä¸ºä»¥ä¸‹ç±»å‹ä¹‹ä¸€ï¼Œå¹¶æå–å‡ºå¯¹åº”çš„å…·ä½“æ–‡æœ¬å†…å®¹ï¼š

## é‡ç‚¹å…³æ³¨çš„å››ç§ä¸»è¦SysMLå›¾è¡¨ç±»å‹ï¼š

1. **Requirement (éœ€æ±‚):** - æœ€é‡è¦
   - æè¿°ç³»ç»Ÿåº”å®ç°çš„åŠŸèƒ½æˆ–éåŠŸèƒ½çº¦æŸ
   - åŒ…æ‹¬éœ€æ±‚æè¿°ã€ä¼˜å…ˆçº§ã€éªŒè¯æ–¹æ³•
   - åŒ…æ‹¬éœ€æ±‚ä¹‹é—´çš„ä¾èµ–ã€æ´¾ç”Ÿã€éªŒè¯ç­‰å…³ç³»

2. **Block Definition and Internal Block (å—å®šä¹‰å’Œå†…éƒ¨å—):** - æœ€é‡è¦
   - æè¿°ç³»ç»Ÿä¸­çš„ç»“æ„ç»„ä»¶ï¼ˆå—ï¼‰ã€å…¶å±æ€§ã€ç«¯å£ã€æ“ä½œã€ä»¥åŠä¸å…¶ä»–å—çš„å…³ç³»
   - æè¿°å—çš„å†…éƒ¨ç»“æ„ï¼ŒåŒ…æ‹¬éƒ¨ä»¶ã€è¿æ¥å™¨å’Œç«¯å£

3. **Activity (æ´»åŠ¨):** - æœ€é‡è¦
   - æè¿°ç³»ç»Ÿæ‰§è¡Œçš„æ­¥éª¤ã€åŠ¨ä½œã€æ§åˆ¶æµã€å¹¶å‘æˆ–é€‰æ‹©è·¯å¾„
   - åŒ…æ‹¬æ´»åŠ¨æ­¥éª¤ã€å†³ç­–ç‚¹ã€åˆ†æ”¯æ¡ä»¶ã€å¹¶å‘æ´»åŠ¨

4. **State Machine (çŠ¶æ€æœº):** - æœ€é‡è¦
   - æè¿°ç³»ç»Ÿæˆ–ç»„ä»¶çš„è¡Œä¸ºçŠ¶æ€åŠè½¬æ¢ã€çŠ¶æ€åç§°ã€äº‹ä»¶ç­‰
   - åŒ…æ‹¬çŠ¶æ€åç§°ã€è½¬æ¢æ¡ä»¶ã€è§¦å‘äº‹ä»¶

## å…¶ä»–SysMLå›¾è¡¨ç±»å‹ï¼š

5. **Use Case (ç”¨ä¾‹):** 
   - æè¿°ç”¨æˆ·ä¸ç³»ç»Ÿä¹‹é—´çš„äº¤äº’ã€ç³»ç»Ÿæä¾›çš„åŠŸèƒ½ã€å‚ä¸è€…å’Œåœºæ™¯

6. **Parameter (å‚æ•°):** 
   - æè¿°ç³»ç»Ÿå‚æ•°å’Œçº¦æŸå…³ç³»
   - åŒ…æ‹¬æ•°å­¦/ç‰©ç†å…¬å¼ã€çº¦æŸæ¡ä»¶

7. **Sequence (åºåˆ—):** 
   - æè¿°ç»„ä»¶ä¹‹é—´çš„äº¤äº’åºåˆ—
   - åŒ…æ‹¬æ¶ˆæ¯ã€è°ƒç”¨ã€å“åº”ã€è¿”å›å€¼

ä½ çš„è¾“å‡ºå¿…é¡»æ˜¯ä¸€ä¸ªJSONæ ¼å¼çš„ä»»åŠ¡åˆ—è¡¨ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
  "tasks": [
    {{
      "type": "å›¾è¡¨ç±»å‹",
      "content": "æå–çš„å…·ä½“å†…å®¹"
    }}
  ]
}}
"""

USER_PROMPT_EXTRACT_AND_CLASSIFY = """
è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–é€‚åˆåˆ›å»ºå„ç§SysMLå›¾è¡¨çš„å†…å®¹ï¼Œå¹¶æŒ‰ç…§å›¾è¡¨ç±»å‹è¿›è¡Œåˆ†ç±»ï¼š

{text}

è¯·ç¡®ä¿ï¼š
1. å…¨é¢åˆ†ææ–‡æœ¬ï¼Œä¸é—æ¼ä»»ä½•æœ‰ä»·å€¼çš„ä¿¡æ¯
2. å‡†ç¡®åˆ†ç±»æ¯ä¸ªå†…å®¹ç‰‡æ®µåˆ°å¯¹åº”çš„SysMLå›¾è¡¨ç±»å‹
3. æå–çš„å†…å®¹è¶³å¤Ÿè¯¦ç»†ï¼ŒåŒæ—¶å°½é‡ç®€æ´
4. è¾“å‡ºæ ¼å¼ç¬¦åˆè¦æ±‚ï¼Œæ¯ä¸ªä»»åŠ¡æœ‰æ˜ç¡®çš„typeå’Œcontentå­—æ®µ
"""


def get_output_dir() -> str:
    """
    è·å–è¾“å‡ºç›®å½•è·¯å¾„ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
    
    è¿”å›:
        è¾“å‡ºç›®å½•çš„ç»å¯¹è·¯å¾„
    """
    # è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆsrcçš„çˆ¶ç›®å½•ï¼‰
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(os.path.dirname(current_dir))
    
    # è¾“å‡ºç›®å½•è·¯å¾„
    output_dir = os.path.join(project_root, "data", "output")
    
    # å¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œåˆ›å»ºå®ƒ
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        logger.info(f"åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
    
    return output_dir


def save_merged_tasks(tasks: List[SysMLTaskExtraction], output_dir: str = None) -> str:
    """
    ä¿å­˜åˆå¹¶åçš„ä»»åŠ¡åˆ°JSONæ–‡ä»¶
    
    å‚æ•°:
        tasks: ä»»åŠ¡åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰
        
    è¿”å›:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    try:
        # è·å–è¾“å‡ºç›®å½•
        if output_dir is None:
            output_dir = get_output_dir()
        
        # ç”Ÿæˆæ–‡ä»¶åï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"merged_tasks_{timestamp}.json"
        filepath = os.path.join(output_dir, filename)
        
        # å‡†å¤‡è¦ä¿å­˜çš„æ•°æ®
        tasks_data = {
            "timestamp": timestamp,
            "total_tasks": len(tasks),
            "tasks": []
        }
        
        # è½¬æ¢ä»»åŠ¡æ•°æ®
        for i, task in enumerate(tasks, 1):
            task_data = {
                "index": i,
                "type": task.type,
                "content": task.content,
                "content_length": len(task.content)
            }
            tasks_data["tasks"].append(task_data)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(tasks_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"âœ… åˆå¹¶åçš„ä»»åŠ¡å·²ä¿å­˜åˆ°: {filepath}")
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print(f"\n{'='*80}")
        print(f"ğŸ“ åˆå¹¶ä»»åŠ¡å·²ä¿å­˜")
        print(f"{'='*80}")
        print(f"æ–‡ä»¶è·¯å¾„: {filepath}")
        print(f"ä»»åŠ¡æ€»æ•°: {len(tasks)}")
        print("\nä»»åŠ¡ç±»å‹ç»Ÿè®¡:")
        task_types = {}
        for task in tasks:
            task_types[task.type] = task_types.get(task.type, 0) + 1
        
        for task_type, count in sorted(task_types.items()):
            print(f"  ğŸ“‹ {task_type}: {count} ä¸ª")
        print(f"{'='*80}\n")
        
        return filepath
        
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜åˆå¹¶ä»»åŠ¡å¤±è´¥: {str(e)}", exc_info=True)
        return ""


def classify_chunk(chunk: str, chunk_index: int, llm, output_parser) -> List[SysMLTaskExtraction]:
    """
    å¯¹å•ä¸ªchunkè¿›è¡Œåˆ†ç±»
    
    å‚æ•°:
        chunk: æ–‡æœ¬å—
        chunk_index: å—ç´¢å¼•
        llm: è¯­è¨€æ¨¡å‹
        output_parser: è¾“å‡ºè§£æå™¨
        
    è¿”å›:
        ä»»åŠ¡åˆ—è¡¨
    """
    try:
        logger.info(f"ğŸ” åˆ†ç±»ç¬¬ {chunk_index + 1} ä¸ªchunk")
        
        # ä½¿ç”¨ChatPromptTemplateè€Œä¸æ˜¯PromptTemplate
        prompt = ChatPromptTemplate.from_messages([
            ("system", SYSTEM_PROMPT_EXTRACT_AND_CLASSIFY),
            ("human", USER_PROMPT_EXTRACT_AND_CLASSIFY)
        ])
        
        # åˆ›å»ºé“¾
        chain = prompt | llm | output_parser
        
        # æµå¼è°ƒç”¨
        print(f"\n{'='*80}")
        print(f"ğŸ” æ­£åœ¨åˆ†æ Chunk {chunk_index + 1}...")
        print(f"{'='*80}\n")
        
        # æµå¼è¾“å‡º - æ³¨æ„ï¼šJsonOutputParserçš„streamè¿”å›çš„æ˜¯å­—å…¸å¯¹è±¡
        final_result = None
        for partial_result in chain.stream({"text": chunk}):
            # partial_result æ˜¯ä¸€ä¸ªå­—å…¸å¯¹è±¡ï¼Œä¸æ˜¯å­—ç¬¦ä¸²
            # æ‰“å°å½“å‰çš„éƒ¨åˆ†ç»“æœï¼ˆç¾åŒ–è¾“å‡ºï¼‰
            if isinstance(partial_result, dict):
                # åªåœ¨æœ‰taskså­—æ®µæ—¶æ‰æ‰“å°
                if 'tasks' in partial_result and partial_result['tasks']:
                    print(f"\ræ­£åœ¨ç”Ÿæˆ... å·²è¯†åˆ« {len(partial_result['tasks'])} ä¸ªä»»åŠ¡", end="", flush=True)
                final_result = partial_result
        
        print()  # æ¢è¡Œ
        
        print(f"\n{'='*80}")
        print(f"âœ… Chunk {chunk_index + 1} åˆ†æå®Œæˆ")
        print(f"{'='*80}\n")
        
        # æœ€åä¸€ä¸ªç»“æœå°±æ˜¯å®Œæ•´çš„ç»“æœ
        result = final_result
        
        # ä½¿ç”¨json_repairä¿®å¤å¯èƒ½çš„JSONé—®é¢˜ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if result:
            try:
                result = json.loads(repair_json(json.dumps(result)))
            except Exception as repair_error:
                logger.warning(f"JSONä¿®å¤å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹ç»“æœ: {repair_error}")
        
        # è½¬æ¢ä¸ºSysMLTaskExtractionå¯¹è±¡
        tasks = []
        if result and 'tasks' in result:
            for task_dict in result['tasks']:
                tasks.append(SysMLTaskExtraction(
                    type=task_dict.get('type', ''),
                    content=task_dict.get('content', '')
                ))
        
        logger.info(f"âœ… Chunk {chunk_index + 1} æå–åˆ° {len(tasks)} ä¸ªä»»åŠ¡")
        for i, task in enumerate(tasks, 1):
            logger.info(f"   {i}. {task.type}: {task.content[:50]}...")
        
        return tasks
        
    except Exception as e:
        logger.error(f"âŒ Chunk {chunk_index + 1} åˆ†ç±»å¤±è´¥: {str(e)}", exc_info=True)
        return []


def merge_tasks_by_type(tasks: List[SysMLTaskExtraction]) -> List[SysMLTaskExtraction]:
    """
    æŒ‰ç±»å‹åˆå¹¶ä»»åŠ¡
    
    å‚æ•°:
        tasks: ä»»åŠ¡åˆ—è¡¨
        
    è¿”å›:
        åˆå¹¶åçš„ä»»åŠ¡åˆ—è¡¨
    """
    logger.info(f"ğŸ”„ å¼€å§‹åˆå¹¶ä»»åŠ¡ï¼ŒåŸå§‹ä»»åŠ¡æ•°: {len(tasks)}")
    
    task_groups = defaultdict(list)
    for task in tasks:
        if task.type and task.content:  # ç¡®ä¿typeå’Œcontentéƒ½ä¸ä¸ºç©º
            task_groups[task.type].append(task.content)
    
    merged_tasks = []
    for task_type, contents in task_groups.items():
        merged_content = "\n\n---\n\n".join(contents)
        merged_tasks.append(SysMLTaskExtraction(
            type=task_type,
            content=merged_content.strip()
        ))
        logger.info(f"   ğŸ“¦ {task_type}: åˆå¹¶äº† {len(contents)} ä¸ªå†…å®¹ç‰‡æ®µ")
    
    logger.info(f"âœ… åˆå¹¶å®Œæˆï¼Œæœ€ç»ˆä»»åŠ¡æ•°: {len(merged_tasks)}")
    return merged_tasks


def classify_and_assign_tasks(state: WorkflowState) -> WorkflowState:
    """
    å¯¹chunksè¿›è¡Œåˆ†ç±»å¹¶åˆ†é…ä»»åŠ¡
    
    å‚æ•°:
        state: å½“å‰å·¥ä½œæµçŠ¶æ€
        
    è¿”å›:
        æ›´æ–°åçš„å·¥ä½œæµçŠ¶æ€
    """
    # æ£€æŸ¥è¾“å…¥
    if not state.text_chunks:
        logger.warning("âš ï¸ æ²¡æœ‰æ–‡æœ¬å—å¯ä¾›åˆ†ç±»ï¼Œå°è¯•ä½¿ç”¨expanded_content")
        if state.expanded_content:
            state.text_chunks = [state.expanded_content]
        else:
            state.error_message = "æ²¡æœ‰å¯åˆ†ç±»çš„æ–‡æœ¬å†…å®¹"
            state.status = ProcessStatus.FAILED
            return state
    
    try:
        logger.info(f"ğŸ“‹ å¼€å§‹å¯¹ {len(state.text_chunks)} ä¸ªchunksè¿›è¡Œä»»åŠ¡åˆ†ç±»")
        
        # åˆ›å»ºLLMå’Œè§£æå™¨
        llm = ChatOpenAI(
            model=settings.llm_model,
            api_key=settings.openai_api_key,
            base_url=settings.base_url,
            temperature=0.0,
            streaming=True
        )
        
        output_parser = JsonOutputParser(pydantic_object=SysMLTaskExtractionResult)
        
        # å¯¹æ¯ä¸ªchunkè¿›è¡Œåˆ†ç±»
        all_tasks = []
        for i, chunk in enumerate(state.text_chunks):
            logger.info(f"\n{'='*80}")
            logger.info(f"ğŸ“„ å¤„ç† Chunk {i+1}/{len(state.text_chunks)}")
            logger.info(f"ğŸ“ Chunké•¿åº¦: {len(chunk)} å­—ç¬¦")
            logger.info(f"{'='*80}")
            
            tasks = classify_chunk(chunk, i, llm, output_parser)
            all_tasks.extend(tasks)
        
        logger.info(f"ğŸ“Š æ€»å…±æå–äº† {len(all_tasks)} ä¸ªåŸå§‹ä»»åŠ¡")
        
        # æŒ‰ç±»å‹åˆå¹¶ä»»åŠ¡
        merged_tasks = merge_tasks_by_type(all_tasks)
        logger.info(f"ğŸ”„ åˆå¹¶åæœ‰ {len(merged_tasks)} ä¸ªä»»åŠ¡")
        
        # ä¿å­˜åˆå¹¶åçš„ä»»åŠ¡åˆ°JSONæ–‡ä»¶
        if merged_tasks:
            output_dir = state.output_dir if state.output_dir else None
            saved_file = save_merged_tasks(merged_tasks, output_dir)
            if saved_file and not state.output_dir:
                state.output_dir = os.path.dirname(saved_file)
        
        # è½¬æ¢ä¸ºSysMLTaskå¯¹è±¡
        sysml_tasks = []
        for task in merged_tasks:
            task_id = f"TASK-{uuid.uuid4().hex[:8]}"
            sysml_task = SysMLTask(
                id=task_id,
                type=task.type,
                content=task.content,
                status=ProcessStatus.NOT_STARTED
            )
            sysml_tasks.append(sysml_task)
            
            logger.info(f"ğŸ“ åˆ›å»ºä»»åŠ¡ {task_id}")
            logger.info(f"   ç±»å‹: {task.type}")
            logger.info(f"   å†…å®¹é•¿åº¦: {len(task.content)} å­—ç¬¦")
            logger.info(f"   å†…å®¹é¢„è§ˆ: {task.content[:100]}...")
        
        # æ›´æ–°çŠ¶æ€
        state.assigned_tasks = sysml_tasks
        state.tasks_assigned = True
        
        # æ‰§è¡Œä»»åŠ¡ï¼ˆè°ƒç”¨å„ä¸ªsysml-agentï¼‰
        if sysml_tasks:
            state = execute_sysml_tasks(state)
        else:
            logger.warning("âš ï¸ æ²¡æœ‰æå–åˆ°ä»»ä½•ä»»åŠ¡")
        
        logger.info(f"âœ… ä»»åŠ¡åˆ†ç±»å’Œåˆ†é…å®Œæˆï¼Œå…± {len(sysml_tasks)} ä¸ªä»»åŠ¡")
        return state
        
    except Exception as e:
        logger.error(f"âŒ ä»»åŠ¡åˆ†ç±»å¤±è´¥: {str(e)}", exc_info=True)
        state.error_message = f"ä»»åŠ¡åˆ†ç±»å¤±è´¥: {str(e)}"
        state.status = ProcessStatus.FAILED
        return state


def execute_sysml_tasks(state: WorkflowState) -> WorkflowState:
    """
    æ‰§è¡ŒSysMLä»»åŠ¡ï¼ˆè°ƒç”¨å„ä¸ªagentï¼‰
    
    å‚æ•°:
        state: å½“å‰å·¥ä½œæµçŠ¶æ€
        
    è¿”å›:
        æ›´æ–°åçš„å·¥ä½œæµçŠ¶æ€
    """
    logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œ {len(state.assigned_tasks)} ä¸ªSysMLä»»åŠ¡")

    for task in state.assigned_tasks:
        try:
            logger.info(f"\n{'='*80}")
            logger.info(f"âš™ï¸ æ‰§è¡Œä»»åŠ¡ {task.id}")
            logger.info(f"   ç±»å‹: {task.type}")
            logger.info(f"{'='*80}\n")
            
            task.status = ProcessStatus.PROCESSING
            
            # æ ¹æ®ä»»åŠ¡ç±»å‹è°ƒç”¨å¯¹åº”çš„agent
            if task.type == "Requirement" and requirement_agent:
                state = requirement_agent(state, task.id, task.content)
                
            elif task.type == "Activity" and activity_agent:
                state = activity_agent(state, task.id, task.content)
                
            elif task.type == "Block Definition and Internal Block" and bdd_ibd_agent:
                state = bdd_ibd_agent(state, task.id, task.content)
                
            elif task.type == "State Machine" and state_machine_agent:
                state = state_machine_agent(state, task.id, task.content)
                
            elif task.type == "Use Case" and usecase_agent:
                state = usecase_agent(state, task.id, task.content)
                
            elif task.type == "Parameter" and parameter_agent:
                state = parameter_agent(state, task.id, task.content)
                
            elif task.type == "Sequence" and sequence_agent:
                state = sequence_agent(state, task.id, task.content)
                
            else:
                logger.warning(f"âš ï¸ ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹æˆ–agentä¸å¯ç”¨: {task.type}")
                task.status = ProcessStatus.FAILED
                task.error = f"ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹æˆ–agentä¸å¯ç”¨: {task.type}"
                continue
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            for state_task in state.assigned_tasks:
                if state_task.id == task.id:
                    if state_task.status != ProcessStatus.FAILED:
                        state_task.status = ProcessStatus.COMPLETED
                    logger.info(f"âœ… ä»»åŠ¡ {task.id} æ‰§è¡Œå®Œæˆ")
                    break
                    
        except Exception as e:
            logger.error(f"âŒ ä»»åŠ¡ {task.id} æ‰§è¡Œå¤±è´¥: {str(e)}", exc_info=True)
            task.status = ProcessStatus.FAILED
            task.error = str(e)
    
    logger.info(f"\n{'='*80}")
    logger.info(f"ğŸ‰ æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæˆ")
    logger.info(f"{'='*80}\n")
    
    return state